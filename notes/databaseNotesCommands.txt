alter table "series" add column "search_text" text;

update series set "search_text" = concat(name, descripti
on)

alter table "series" add column "search_vec" TSVECTOR;

alter table "series" add column "dataset_name" text
alter table "categories" add column "dataset_name" text

I need to specify english when vectorizing. after that I don't need to
specify english when making the query or the index (if I store the vectors in a column )
update series set search_vec = to_tsvector('english',search_text);

--should not work-- update series set search_vec = to_tsvector(search_text);


from this resource:
https://austingwalters.com/fast-full-text-search-in-postgresql/


CREATE INDEX series_vec_index ON series USING gin(search_vec);


SELECT "series"."series_id" AS "series_series_id", "series"."name" AS "series_name", "series"."units" AS "series_units", "series"."f" AS "series_f", "series"."description" AS "series_description", "series"."copyright" AS "series_copyright", "series"."source" AS "series_source", "series"."iso3166" AS "series_iso3166", "series"."geography" AS "series_geography", "series"."start" AS "series_start", "series"."end" AS "series_end", "series"."last_updated" AS "series_last_updated", "series"."geoset_id" AS "series_geoset_id", "series"."data" AS "series_data" FROM "public"."series" "series" WHERE series.search_vec @@ to_tsquery(%Electricity%)

--these are the dataset category id's

with recursive datasets 
    as (select category_id, parent_category_id, name from categories where category_id 
    in (964165,1370522,2102233,2227112,2641361,3161918,3604304,3535005,717234,2123635,0,
        2251604,2631064,2134384,714804,2889994,714755,1292190,40203,829714,711224) 
    union select c.category_id, c.parent_category_id, d.name 
    from categories c inner join datasets d on d.category_id = c.parent_category_id) 
    update categories set dataset_name = dsets.name 
    from (select parent_category_id, category_id, name from datasets ) as dsets 
    where categories.category_id = dsets.category_id;



****************************** DON'T NEED TO RUN THIS, JUST FOR ILLUSTRATION *************************************
gets table expanded from childseries array--on element from array per row matched with name and id
select elem, name, category_id, dataset_name from (select * from categories limit 50) as sub_cat , jsonb_array_elements(childseries)
as elem;
******************************************************************************************************


    
      
with cats 
    as (select substr(cast(childseries_id as text), 2,length(cast(childseries_id as text)) - 2) childseries_id, name, category_id, dataset_name 
    from (select * from categories) as sub_cat ,jsonb_array_elements(childseries) as childseries_id) 
    update series
        set dataset_name = selectcats.dataset_name
        from ( select dataset_name, childseries_id from cats ) as selectcats
    where series.series_id = selectcats.childseries_id



*************************************** TEST returns 0 rows *******************************************************
with cats
    as (select childseries_id, name, category_id, dataset_name
    from (select * from categories limit 50) as sub_cat , jsonb_array_elements(childseries) as childseries_id) select c.dataset_name, c.childseries_id, s.series_id from cats c join series s on cast(c.childseries_id as text) = s.series_id;

update series 
    set dataset_name = cast(subquery.name as text)
        from (select childseries_id, name, category_id, dataset_name 
            from (select * from categories limit 50) as sub_cat , jsonb_array_elements(childseries) as childseries_id) 
                as subquery where series.series_id = cast(subquery.childseries_id as text);


Drop index series_vec_index
alter table "series" drop column "search_text";
alter table "series" add column "search_text" text;

might need to run this again because text is concatenated without space 
update series set "search_text" = concat(name, ' ', description, ' ',dataset_name);

alter table "series" drop column "search_vec";
alter table "series" add column "search_vec" TSVECTOR;

update series set search_vec = to_tsvector('english',search_text);
CREATE INDEX series_vec_index ON series USING gin(search_vec); 


needed to delect duplicate international energy outlook 2019 with no child categories:
delete from categories where category_id = 3535005;

Make indexes for filters (use pattern for left-anchored wildcards):

create index frequency_index on series(f text_pattern_ops); 
create index units_index on series(units text_pattern_ops);
create index dataset_name_index on series(dataset_name text_pattern_ops);
create index geography_index on series(geography text_pattern_ops);

# datasets that I imported into the categories table have childseries as null instead
of empty array []. need to change this for check when rendering the tree.
update categories set childseries = '[]' where childseries is null;

add array of ancestory categories to category records:

alter table categories add column ancestors integer[];


****************
This is for making the ancestors array of category_ids

WITH RECURSIVE tree (category_id, ancestors, depth, cycle) AS (
            SELECT category_id, '{}'::integer[], 0, FALSE
            FROM categories WHERE parent_category_id = 371
          UNION ALL
            SELECT
              n.category_id, t.ancestors || n.parent_category_id, t.depth + 1,
              n.parent_category_id = ANY(t.ancestors)
            FROM categories n, tree t
            WHERE n.parent_category_id = t.category_id
            AND NOT t.cycle
        )
        UPDATE categories
            SET ancestors = q.ancestors
            FROM ( SELECT t.ancestors, t.category_id FROM tree t) as q
            WHERE categories.category_id = q.category_id;

**********************
this is for making the ancestor_names array of ancestor names

**first**
ALTER table categories ADD COLUMN ancestor_names text[];

**then**

WITH RECURSIVE tree (category_id, name, ancestors, ancestor_names, depth, cycle) AS (
            SELECT category_id, name, ancestors, '{}'::text[], 0, FALSE
            FROM categories WHERE parent_category_id = 371
        UNION ALL
            SELECT  
                n.category_id, n.name, n.ancestors, t.ancestor_names || t.name, t.depth + 1,
                n.parent_category_id = ANY(t.ancestors)
            FROM categories n, tree t 
            WHERE n.parent_category_id = t.category_id
            AND NOT t.cycle
            )
           UPDATE categories
                SET ancestor_names = q.ancestor_names
                FROM ( SELECT t.ancestor_names, t.category_id FROM tree t) as q
                WHERE categories.category_id = q.category_id; 



elect * from categories where 'USA' in (select geography from temp_cats where temp_cats.category_id = 1372273);
*** NOT USED
CREATE TABLE cat_series_filters AS
SELECT c.name, c.category_id, c.ancestors, s.f, s.geography  
FROM 
    categories c
    JOIN series s
        ON s.series_id IN 
            (SELECT 
                jsonb_array_elements_text(c.childseries));
********
select * from categories where parent_category_id = 2804614
AND 'A' IN (SELECT f from temp_cats where temp_cats.category_id = 2804614);

CREATE TABLE temp_cats AS
SELECT c.name, c.category_id, c.ancestors, jsonb_array_elements_text(c.childseries) as series_id
from categories c;

ALTER TABLE temp_cats
ADD COLUMN f character varying(120),
ADD COLUMN geography text;

UPDATE temp_cats SET f = series.f, geography = series.geography
FROM series 
WHERE temp_cats.series_id = series.series_id;

*******THIS WAS A MISTAKE (corrected below)*********
UPDATE temp_cats SET geography = 'USA' 
WHERE series_id LIKE 'AEO%';

*********CORRECTION**********
UPDATE temp_cats SET geography = '' WHERE series_id like 'AEO%' 
AND series_id not like '%USA%';

---some series have no geography. I filled in usa for the AEOs, but total energy,
coal, and natural gas also have some unidentified records

****THIS WAS A MISTAKE (Corrected below)*****
UPDATE series SET geography = 'USA' 
WHERE series_id LIKE 'AEO%';

*******CORRECTION*******
UPDATE series SET geography = '' WHERE dataset_name LIKE 'Annual Energy%' 
    AND series_id NOT LIKE '%USA%';


CREATE TABLE interior_treenode_filters AS
SELECT c.name, c.category_id, unnest(c.ancestors) as ancestors, c.series_id, c.f, c.geography
from temp_cats c;

******CORRECTION FOR MAKEING ALL AEO have 'USA' geography**********
UPDATE interior_treenode_filters SET geography = '' WHERE series_id LIKE 'AEO%'
AND series_id NOT LIKE '%USA%';


create index category_id_index on temp_cats(category_id);
create index ancestor_index on interior_treenode_filters(ancestors);
create index geography_filter_index on interior_treenode_filters(geography);

INSERT INTO interior_treenode_filters (name, ancestors, series_id, f, geography)
SELECT name, category_id, series_id, f, geography from interior_treenode_filters;



create table frequency_filter as
SELECT DISTINCT ancestors as category_id, f from interior_treenode_filters;

create table geography_filter as
SELECT DISTINCT ancestors as category_id, geography from interior_treenode_filters;

****CORRECTION TO AEO USA geography issue*******THIS DIDN'T WORK! HAD TO RECREATE TABLE
UPDATE geography_filter SET geography = i.geography 
FROM interior_treenode_filters i 
WHERE 
geography_filter.category_id = i.ancestors;


*** Drop unused indexes!!! ***

CREATE INDEX geography_filter_index on geography_filter(geography);
CREATE INDEX frequency_filter_index on frequency_filter(f);

ALTER TABLE geography_filter ADD COLUMN id SERIAL PRIMARY KEY;
ALTER TABLE frequency_filter ADD COLUMN id SERIAL PRIMARY KEY;

create table category_leaf_lookup as
select category_id as leaf_category, unnest(ancestors) as ancestors from categories where jsonb_array_length(childseries) > 0;
ALTER TABLE category_leaf_lookup ADD COLUMN id SERIAL PRIMARY KEY;

CREATE INDEX leaf_category_index on category_leaf_lookup(leaf_category);

INSERT INTO category_leaf_lookup (leaf_category, ancestors)
SELECT DISTINCT on (leaf_category) leaf_category, 371 from category_leaf_lookup;



ALTER TABLE categories ADD COLUMN parent_name text;

UPDATE categories c1
SET parent_name = c2.name
FROM categories c2 
WHERE c2.category_id = c1.parent_category_id;

---add indexes to the series table. We query these columns in the 'getManySeries' series service 

CREATE INDEX series_geography_index on series(geography);
CREATE INDEX series_frequency_index on series(f);



'AEO.2020.LORENCST.EMI_CO2_COMM_NA_CL_NA_ENC_MILLMETNCO2.A','AEO.2020.LORENCST.EMI_CO2_COMM_NA_ELC_NA_ENC_MILLMETNCO2.A','AEO.2020.LORENCST.EMI_CO2_COMM_NA_NA_NA_ENC_MILLMETNCO2.A','AEO.2020.LORENCST.EMI_CO2_COMM_NA_NG_NA_ENC_MILLMETNCO2.A','AEO.2020.LORENCST.EMI_CO2_COMM_NA_PET_NA_ENC_MILLMETNCO2.A','AEO.2020.LORENCST.EMI_CO2_ELEP_NA_CL_NA_ENC_MILLMETNCO2.A','AEO.2020.LORENCST.EMI_CO2_ELEP_NA_NA_NA_ENC_MILLMETNCO2.A','AEO.2020.LORENCST.EMI_CO2_ELEP_NA_NG_NA_ENC_MILLMO2_ELEP_NA_PET_NA_ENC_MILLMETNCO2.A','AEO.2020.LORENCST.EMI_CO2_IDAL_NA_CL_NA_ENC_MILLMETNCO2.A','AEO.2020.LORENCST.EMI_CO2_IDAL_NA_ELC_NA_ENC_MILLMETNCO2.A'
*** NOT USED. THESE RECORDS WERE MISSING BECUASE THEY HAD NO CHILDSERIES (MISSING DATA ***

INSERT INTO leaf_category_lookup (category_id, ancestors)
SELECT category_id, 3625142 from categories where 3625142 = any(ancestors) and jsonb_array_length(childseries) > 0; 
**************************************************

for tree builder --
where category_id not in (...excluded_array)
for keyword search -- 
where not exists (select ancestors from leaf_category_lookup where category_id = :treeNode)
intersect (...excluded_array)
where category_id not in (select category_id from leaf_category_lookup 
        where ancestors in (:...excluded_array))

\copy (SELECT DISTINCT ON (units) units, series_id, name, dataset_name from series) to 'units.csv' csv header

*** category_id is 'data_group' id ***


Nested Loop  (cost=0.00..166024843973.85 rows=202718509838 width=126)
   Join Filter: (SubPlan 1)
   ->  Seq Scan on categories c  (cost=0.00..39782.49 rows=145249 width=699)
   ->  Materialize  (cost=0.00..1538293.86 rows=2791324 width=59)
         ->  Seq Scan on series s  (cost=0.00..1494352.24 rows=2791324 width=59)
   SubPlan 1
     ->  ProjectSet  (cost=0.00..0.52 rows=100 width=32)
           ->  Result  (cost=0.00..0.01 rows=1 width=0)
 JIT:
   Functions: 13
   Options: Inlining true, Optimization true, Expressions true, Deforming true
(11 rows)

******* Below is to fix error in geography_filter: some categories think they have USA data in their 
childseries, but they do not (because I incorrectly set geography to USA for all series in the AEOs 
before I constructed the geography filter). I'm going to go through the whole process of building these filters again,
cleaning up the code as I go . . . ****

SELECT a.* 
FROM temp_cats a 
JOIN (SELECT series_id, category_id, COUNT(*)
FROM temp_cats
GROUP BY series_id, category_id
HAVING count(*) > 1) b 
ON a.series_id = b.series_id
AND a.category_id = b.category_id
ORDER BY a.series_id

to insert default user
INSERT INTO public.user VALUES ('2d8a7e18-4567-46f5-9079-e8438e6d756b', 'demo@demo.com', '$2a$08$Rk2FjkKnztNIyw4HBkOVsu7YAXUT9YUhiVBnQnDew1jsInmxAfYbu', '2021-03-19 04:45:56.177355')

I need to select only a few columns when I do select, and make sure that
these columns have indexes. That way the whole table does not need to be 
transferred to memory when I query.

Looks like coal and petroleum (maybe some others have no geography data. They will be
excluded from all queries. May have to look into this later)

EXPLAIN ANALYZE results (before building vectors with 'english'--so I think that the index is not usable)
--query searching for electricity with limit 50 does not use index (seq scan) and is fast. 
--query searching for electricity with no limit does not use index and is slow
--query searching for 'aeo' limit 50 uses index (how can it get the index--I thought it can't access because I didn't use
'english' when I build the vector) and is fast and returns no results. maybe it uses the index because it knows from statistics
that 'aeo' probably doesn't exist, therefore index overhead is worthwhile.

What about phrase search?

should impement a trigger to handle inserting or updating data
--will this make it so I don't have to rebuild the index each time?

what about weighting the colums? name + description from series gets more weight than category . . .?
right now search pulls series.data, but I don't need that--considger pulling thousands of jsonbs out, 
that is very expensive . . .


might need to join series with datasets to get expanded titles
start with dataset id--this is the root. then recursively join all categories, matching 
'parent_category' first with root dataset id, then walking down the tree. this should 
give me all categories that fall under the root dataset (AEO2014, for example). then
get all the series belonging to all the categories in my current set (child_series). 
each of those child series then need to have the 'name' of the root dataset added to 
its seach_text, then needs to be revectorized.

NOTE! users searching for the name (or keywords contained in name) of a top level dataset
might not want to get all series returned--too much noise. we should implement a 'category' 
search that will return categories.

And connect search with the tree structure so that a user can walk down the tree hierachy
and then search everything below. Should we implement this query with joins? will it be to 
slow? right now categories have pointers to series, but not the other way. Should I add a 
'parent category' field to each series? 

--maybe there is a reason EIA did not implement this. series are not meant to be searched,
we should stop at the lowest leaf category . . . 

need to check capitalization, phrases in full text search.
might need to add parent category name to series search_text

query for filters 'Annual Energy Outlook 2014' and 'quads' took very long time. Finally returned no 
records. why did it take so long? 

select * from series 
WHERE search_vec @@ phraseto_tsquery('test') AND f LIKE '%' AND units LIKE '%' AND dataset_name LIKE 'Annual Energy Outlook 2014' AND geography LIKE '%' LIMIT 50;

.andWhere('COALESCE(COALESCE(series.id, :string) IN childseries, TRUE)'
    , {
        childSeries: childseries,
        string: '',
      })
## this index was missing, it looks like the app is running faster after adding this
create index category_leaf_lookup_ancestors on category_leaf_lookup(ancestors);

## we use dataset_name and parent_category_id in where clause too
## haven't put these on the server yet, not sure if they are working
create index dataset_name on categories(dataset_name);
create index parent_category_id on categories(parent_category_id);


insert into categories (name, category_id) values ('root category', 371);
update categories set parent_category_id = 371 where parent_category_id is null;

alter table categories
add column excluded integer;

update categories set excluded = 0;
update categories set excluded = 1 where category_id IN (3604312, 3604307, 3604309, 3604310, 3604306, 3604311, 3604314, 3604308,
      1019945, 1019952, 1019936, 1019950, 964167, 1019955, 1019937, 1019940, 1019943, 1019944, 1019951, 1019956,
      1019953, 1019957, 1019946, 1019960, 1019935, 1019938, 1019961, 1019934, 1019939, 1019959, 1019958, 1019954,
      964168, 1019942, 964169, 1019933,
      1370526,
      1370524,
      1370529,
      1370528,
      1370525,
      1370527,
      2102242,
      2102244,
      2102240,
      2102239,
      2102238,
      2102236,
      2102237,
      2102243,
      2112192,
      2113095,
      2113110,
      2113097,
      2113099,
      2113096,
      2113109,
      2113098,
      2113100,
      2102235,
      2102241,
      2227121,
      2227115,
      2227117,
      2227119,
      2397068,
      2227116,
      2227118,
      2227120,
      2783667,
      2656298,
      2641376,
      2824166,
      2824167,
      2641369,
      2804640,
      2811053,
      2641363,
      2641370,
      2641365,
      2641372,
      2641367,
      2641374,
      2783665,
      2783666,
      2811052,
      2641364,
      2641371,
      2641366,
      2641373,
      2641368,
      2641375,
      2783663,
      2783664,
      2811051,
      2804637,
      2804638,
      2783661,
      2783662,
      2804641,
      3161920,
      3161922,
      3161924,
      3161921,
      3161923,
      3161925);

      CREATE FUNCTION count_estimate(query text)
  RETURNS integer
  LANGUAGE plpgsql AS
$func$
DECLARE
    rec   record;
    rows  integer;
BEGIN
    FOR rec IN EXECUTE 'EXPLAIN ' || query LOOP
        rows := substring(rec."QUERY PLAN" FROM ' rows=([[:digit:]]+)');
        EXIT WHEN rows IS NOT NULL;
    END LOOP;

    RETURN rows;
END
$func$;

## Use like this: 
SELECT count_estimate('...query');


DELETE FROM
	frequency_filter a
		USING frequency_filter b
WHERE
	a.id < b.id
	AND a.category_id = b.category_id
	AND a.f = b.f;

    DELETE FROM 
	geography_filter a 
		USING geography_filter b
WHERE
	a.id < b.id
	AND a.category_id = b.category_id
	AND a.geography = b.geography;

DELETE FROM geography_filter WHERE geography IS NULL;

ALTER TABLE series ADD COLUMN category_id ... forign key 



*******
SET series.category_id = categories.category_id 
WHERE series.series_id IN categories.childseries;

with child_series (category_id, childseries) as (
    SELECT category_id, jsonb_array_elements_text(childseries)
    FROM categories
)
SELECT count(childseries) from child_series
inner join series ON 
series.series_id = child_series.childseries
group by category_id;


SELECT child_series.category_id, series.series_id, series.name from child_series

I will need a many to many table ---series_cat 
******TRY THIS *********
CREATE TABLE series_cat (
  category_id int REFERENCES categories (category_id) ON UPDATE CASCADE ON DELETE CASCADE
, series_id text REFERENCES series (series_id) ON UPDATE CASCADE
, CONSTRAINT series_cat_pkey PRIMARY KEY (category_id, series_id)  
);

******Populate table with many to many relationship******

CREATE INDEX series_cat_series_id on series_cat(series_id);
CREATE INDEX series_cat_category_id on series_cat(category_id);

with child_series (category_id, childseries) as (

    SELECT category_id, jsonb_array_elements_text(childseries)
    FROM categories
)
insert into series_cat (category_id, series_id)
SELECT category_id, childseries from child_series, series
WHERE child_series.childseries = series.series_id;




ERROR:  insert or update on table "series_cat" violates foreign key constraint "series_cat_series_id_fkey"
DETAIL:  Key (series_id)=(PET_IMPORTS.CTY_BO-PP_1-ALL.A) is not present in table "series".
demo=# select * from series where series_id = PET_IMPORTS.CTY_BO-PP_1-ALL.A;
ERROR:  syntax error at or near "."
LINE 1: ...from series where series_id = PET_IMPORTS.CTY_BO-PP_1-ALL.A;

insert into series_cat (category_id, series_id) values (1, 'PET_IMPORTS.CTY_BO-PP_1-ALL.A')
on conflict do nothing;

https://stackoverflow.com/questions/58624935/how-to-skip-exception-raised-in-insert-statement
ON CONFLICT only deals with unique constraints, it doesn't work for check constraints (or foreign key constraints). 

This series id in categories table but not series table
PET_IMPORTS.CTY_BO-PP_1-ALL.A, so I put ON CONFLICT DO NOTHING.
possibly there are other porblematic series id in the categories table

international energy outlook does not show up in tree because it has no entries in
the geography_filter table. Two things:
1. how do I add geography info for the future when we want to search for internation data
2. right now it is excluded and that is ok because we are showing US only data
  a. is there US data in the international energy outlook we should be showing?
    --the answer is yes. I need to run the recursive query to populate the geography filter 
    table on only the IEOs


Annual energy outlook 2021 should not be the dataset name for electricity. And it's in
the search vec as well. I should fix this before recreating the gin

delete duplicate categories and series
--this is causing the lingering datacards . . .
interaction of three problems --duplicate AEO 2021 data, AEO2021 as parent when it 
shouldn't be, react behavior with duplicate data.

SELECT
    category_id, COUNT( category_id )
FROM
    geography_filter    
GROUP BY
    category_id
HAVING
    COUNT( category_id )> 4
ORDER BY
    category_id;

select * from categories where dataset_name = 'Annual Energy Outlook 2021' 
AND NOT ('Annual Energy Outlook 2021' = ANY (ancestor_names));

category_id        | 0
parent_category_id | 371
name               | Electricity
notes              | 
childseries        | []
dataset_name       | Annual Energy Outlook 2021
search_text        | Electricity Annual Energy Outlook 2021
search_vec         | '2021':5 'annual':2 'electr':1 'energi':3 'outlook':4
ancestors          | {}
parent_name        | 
excluded           | 0
ancestor_names     | {}



***FOR adding keywords to inverted index*****
is IEO 2020 not in the EIA api?

UPDATE categories set "dataset_name" = 'Electricity' 
WHERE category_id = 0;

UPDATE categories set "search_text" = concat(name, ' ', dataset_name) where category_id = 0;
UPDATE categories set "search_vec" = to_tsvector('english',search_text) where category_id = 0;

UPDATE categories set "search_text" = concat(name, ' ', dataset_name) where search_text is null;
UPDATE categories set "search_vec" = to_tsvector('english',search_text) where search_vec is null;


update categories set "search_text" = concat(search_text, ' ', 'AEO', ' ', 'AEO2021') 
where dataset_name = 'Annual Energy Outlook 2021';

update categories set "search_text" = concat(search_text, ' ', 'AEO', ' ', 'AEO2020') 
where dataset_name = 'Annual Energy Outlook 2020';

update categories set "search_text" = concat(search_text, ' ', 'AEO', ' ', 'AEO2019') 
where dataset_name = 'Annual Energy Outlook 2019';

update categories set "search_text" = concat(search_text, ' ', 'AEO', ' ', 'AEO2018') 
where dataset_name = 'Annual Energy Outlook 2018';

update categories set "search_text" = concat(search_text, ' ', 'AEO', ' ', 'AEO2017') 
where dataset_name = 'Annual Energy Outlook 2017';

update categories set "search_text" = concat(search_text, ' ', 'AEO', ' ', 'AEO2016') 
where dataset_name = 'Annual Energy Outlook 2016';

update categories set "search_text" = concat(search_text, ' ', 'AEO', ' ', 'AEO2015') 
where dataset_name = 'Annual Energy Outlook 2015';

update categories set "search_text" = concat(search_text, ' ', 'AEO', ' ', 'AEO2014') 
where dataset_name = 'Annual Energy Outlook 2014';


UPDATE categories set "search_vec" = to_tsvector('english',search_text) 
where dataset_name = 'Annual Energy Outlook 2021';

UPDATE categories set "search_vec" = to_tsvector('english',search_text) 
where dataset_name = 'Annual Energy Outlook 2020';

UPDATE categories set "search_vec" = to_tsvector('english',search_text) 
where dataset_name = 'Annual Energy Outlook 2019';

UPDATE categories set "search_vec" = to_tsvector('english',search_text) 
where dataset_name = 'Annual Energy Outlook 2018';

UPDATE categories set "search_vec" = to_tsvector('english',search_text) 
where dataset_name = 'Annual Energy Outlook 2017';

UPDATE categories set "search_vec" = to_tsvector('english',search_text) 
where dataset_name = 'Annual Energy Outlook 2016';

UPDATE categories set "search_vec" = to_tsvector('english',search_text) 
where dataset_name = 'Annual Energy Outlook 2015';

UPDATE categories set "search_vec" = to_tsvector('english',search_text) 
where dataset_name = 'Annual Energy Outlook 2014';



update categories set "search_text" = concat(search_text, ' ', 'IEO') 
where dataset_name = 'International Energy Outlook';

update categories set "search_text" = concat(search_text, ' ', 'IEO2017') 
where 'International Energy Outlook 2017' = any(ancestor_names);

update categories set "search_text" = concat(search_text, ' ', 'IEO2017') 
where name = 'International Energy Outlook 2017';

update categories set "search_text" = concat(search_text, ' ', 'IEO2019') 
where name = 'International Energy Outlook 2019';

update categories set "search_text" = concat(search_text, ' ', 'IEO2019') 
where 'International Energy Outlook 2019' = any(ancestor_names);

UPDATE categories set "search_vec" = to_tsvector('english',search_text) 
where dataset_name = 'International Energy Outlook';

update categories set "search_text" = concat(search_text, ' ', 'STEO') 
where dataset_name = 'Short-Term Energy Outlook';

UPDATE categories set "search_vec" = to_tsvector('english',search_text) 
where dataset_name = 'Short-Term Energy Outlook';

DROP INDEX categories_vec_index;

CREATE INDEX categories_vec_index ON categories USING gin (search_vec);



SELECT
    indexname,
    indexdef
FROM
    pg_indexes
WHERE
    tablename = 'categories';



***do all updates to search text then drop search vec, rebuild, drop GIN, rebuild
might not need to drop before update
alter table "series" drop column "search_vec";
update series set search_vec = to_tsvector('english',search_text);
drop index first?
CREATE INDEX series_vec_index ON series USING gin(search_vec);

****** ADD Indexes to the category_id columns of the frequency and 
        Geography filter tables. These are use for joins ************

CREATE INDEX geography_filter_category_id on geography_filter(category_id);
CREATE INDEX frequency_filter_category_id on frequency_filter(category_id);







